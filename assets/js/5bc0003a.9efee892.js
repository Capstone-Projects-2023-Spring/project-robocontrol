"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[8794],{3905:(e,t,o)=>{o.d(t,{Zo:()=>h,kt:()=>u});var r=o(7294);function n(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function i(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,r)}return o}function a(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?i(Object(o),!0).forEach((function(t){n(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,r,n=function(e,t){if(null==e)return{};var o,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)o=i[r],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)o=i[r],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var c=r.createContext({}),l=function(e){var t=r.useContext(c),o=t;return e&&(o="function"==typeof e?e(t):a(a({},t),e)),o},h=function(e){var t=l(e.components);return r.createElement(c.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var o=e.components,n=e.mdxType,i=e.originalType,c=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),d=l(o),m=n,u=d["".concat(c,".").concat(m)]||d[m]||p[m]||i;return o?r.createElement(u,a(a({ref:t},h),{},{components:o})):r.createElement(u,a({ref:t},h))}));function u(e,t){var o=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=o.length,a=new Array(i);a[0]=m;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:n,a[1]=s;for(var l=2;l<i;l++)a[l]=o[l];return r.createElement.apply(null,a)}return r.createElement.apply(null,o)}m.displayName="MDXCreateElement"},9380:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var r=o(7462),n=(o(7294),o(3905));const i={sidebar_position:2},a="System Block Diagram",s={unversionedId:"requirements/system-block-diagram",id:"requirements/system-block-diagram",title:"System Block Diagram",description:"The design diagram of the combination of RoboControl Robot's external components are shown in Figure 1. The Raspberry Pi acts as the controller for the system, managing the connections to other components and peripherals. It is connected to geared motors, which in turn are connected to tank treads, providing the robot with mobility. The Raspberry Pi is also connected to the five servos, which are responsible for providing precise control over the position and movement of the robot arm. The servos receive a control signal from the Raspberry Pi, specifying the desired position of the robot arm, and then move the robot arm to the desired position, holding it at this orientation for precise control.",source:"@site/docs/requirements/system-block-diagram.md",sourceDirName:"requirements",slug:"/requirements/system-block-diagram",permalink:"/project-robocontrol/docs/requirements/system-block-diagram",draft:!1,editUrl:"https://github.com/Capstone-Projects-2023-Spring/project-robocontrol/edit/main/documentation/docs/requirements/system-block-diagram.md",tags:[],version:"current",lastUpdatedBy:"Ryan Hodge",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"docsSidebar",previous:{title:"System Overview",permalink:"/project-robocontrol/docs/requirements/system-overview"},next:{title:"General Requirements",permalink:"/project-robocontrol/docs/requirements/general-requirements"}},c={},l=[],h={toc:l};function d(e){let{components:t,...i}=e;return(0,n.kt)("wrapper",(0,r.Z)({},h,i,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"system-block-diagram"},"System Block Diagram"),(0,n.kt)("p",null,(0,n.kt)("img",{src:o(8132).Z,width:"942",height:"570"})),(0,n.kt)("p",null,"The design diagram of the combination of RoboControl Robot's external components are shown in Figure 1. The Raspberry Pi acts as the controller for the system, managing the connections to other components and peripherals. It is connected to geared motors, which in turn are connected to tank treads, providing the robot with mobility. The Raspberry Pi is also connected to the five servos, which are responsible for providing precise control over the position and movement of the robot arm. The servos receive a control signal from the Raspberry Pi, specifying the desired position of the robot arm, and then move the robot arm to the desired position, holding it at this orientation for precise control. "),(0,n.kt)("p",null,"The Raspberry Pi also connects to a camera module and an ultrasonic distance sensor module, which enable the robot to gather information about its environment. The camera module allows the robot to capture visual data and process it for various tasks, while the ultrasonic sensor module provides information about distances and obstacles in the robot's surroundings. The Raspberry Pi also connects to a power supply, which provides the necessary power for the components to function. "),(0,n.kt)("p",null,(0,n.kt)("img",{src:o(5320).Z,width:"936",height:"528"})),(0,n.kt)("p",null,"Figure 2 showcases the communication pathway between the Raspberry Pi and the server. The server comprises of the OpenCV python code and a graphical user interface (GUI) website and will be hosted using an Amazon Web Services EC2 instance. These blocks will not be running on the Raspberry Pi to save resources when controlling the motors and servos. The Raspberry Pi acts as the interface between the robot's physical components, including the camera module and ultrasonic sensor module, and the server. It receives environmental data from the camera and ultrasonic modules in the form of images and distances respectively. This data is then transmitted to the OpenCV software for analysis with algorithms. The OpenCV algorithms process the data to determine appropriate motor speeds, which are subsequently sent back to the Raspberry Pi. A visualization of the algorithms being used in the OpenCV code will be sent to the GUI and displayed to the user for more information."),(0,n.kt)("p",null,"The GUI serves as the primary means of interaction with the robot. The GUI receives two different types of data from the OpenCV code: algorithm images and sensor data. Algorithm images will be useful to the user, as these will be displayed to show what process the server is undertaking to detect a possible path. Sensor data will be used to display the real-time video from the robot as well as whether there are any obstructions visible to the ultrasonic distance sensor or not. The GUI will have input buttons, which should be able to command the robot to perform certain actions such as driving forwards, turning, and more. "),(0,n.kt)("p",null,"All the data communication and transmission occurring in this diagram will be accomplished through the WebSocket protocol in python and JavaScript. Since the robot code is written in Python and the OpenCV code will also be, the team will utilize Python\u2019s WebSocket library for communication purposes. In the GUI, JavaScript\u2019s WebSocket library will be utilized to communicate between both the OpenCV code and the Raspberry Pi code."))}d.isMDXComponent=!0},5320:(e,t,o)=>{o.d(t,{Z:()=>r});const r=o.p+"assets/images/CommandFlowDiagram-ef636481736d0d9af8acd82223fd0c39.png"},8132:(e,t,o)=>{o.d(t,{Z:()=>r});const r=o.p+"assets/images/RaspberryPiDiagram-55301d8ab7164f01c58e2a388cc9e7ad.png"}}]);